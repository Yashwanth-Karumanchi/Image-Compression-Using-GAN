{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34h3FwIETevL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.utils as vutils\n",
        "import os\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import tifffile as tiff\n",
        "\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import time\n",
        "import cv2 as cv\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "from math import log10, sqrt\n",
        "\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CH6oQoqoGrty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7021f625-acc3-4e55-b238-301226d813ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "d4SuYDjRTj8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder Model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,num_channels_in_encoder):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # ENCODER\n",
        "\n",
        "        # 64x64x64\n",
        "        self.e_conv_1 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 2, 1, 2)),\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5, 5), stride=(2, 2)),nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        # 128x32x32\n",
        "        self.e_conv_2 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 2, 1, 2)),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(5, 5), stride=(2, 2)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        # 128x32x32\n",
        "        self.e_block_1 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "        # 128x32x32\n",
        "        self.e_block_2 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "        # 128x32x32\n",
        "        self.e_block_3 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "        # 32x32x32\n",
        "        self.e_conv_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=num_channels_in_encoder, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        ec1 = self.e_conv_1(x)\n",
        "        ec2 = self.e_conv_2(ec1)\n",
        "        eblock1 = self.e_block_1(ec2) + ec2\n",
        "        eblock2 = self.e_block_2(eblock1) + eblock1\n",
        "        eblock3 = self.e_block_3(eblock2) + eblock2\n",
        "        ec3 = self.e_conv_3(eblock3)  # in [-1, 1] from tanh activation\n",
        "        return ec3"
      ],
      "metadata": {
        "id": "VG-xmjTcTosU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator / Decoder Model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,num_channels_in_encoder):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # 128x64x64\n",
        "        self.d_up_conv_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=num_channels_in_encoder, out_channels=64, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=128, kernel_size=(2, 2), stride=(2, 2))\n",
        "        )\n",
        "\n",
        "        # 128x64x64\n",
        "        self.d_block_1 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "        # 128x64x64\n",
        "        self.d_block_2 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "        # 128x64x64\n",
        "        self.d_block_3 = nn.Sequential(\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "        # 256x128x128\n",
        "        self.d_up_conv_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ZeroPad2d((1, 1, 1, 1)),\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=128, kernel_size=(2, 2), stride=(2, 2))\n",
        "        )\n",
        "\n",
        "        # 3x128x128\n",
        "        self.d_up_conv_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.ReflectionPad2d((3, 3, 3, 3)),\n",
        "            nn.Conv2d(in_channels=16, out_channels=3, kernel_size=(3, 3), stride=(1, 1)),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        uc1 = self.d_up_conv_1(x)\n",
        "        dblock1 = self.d_block_1(uc1) + uc1\n",
        "        dblock2 = self.d_block_2(dblock1) + dblock1\n",
        "        dblock3 = self.d_block_3(dblock2) + dblock2\n",
        "        uc2 = self.d_up_conv_2(dblock3)\n",
        "        dec = self.d_up_conv_3(uc2)\n",
        "        return dec"
      ],
      "metadata": {
        "id": "RBSaYseVTqIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_read(path):\n",
        "  image = Image.open(path)\n",
        "  if image.mode in (\"RGBA\", \"LA\") or (image.mode == \"P\" and \"transparency\" in image.info) or image.mode == \"L\":\n",
        "      # Convert the image to RGB format\n",
        "      image = image.convert(\"RGB\")\n",
        "  return image"
      ],
      "metadata": {
        "id": "qFXW-w1wTrjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_image(image):\n",
        "  width, height = (image.width, image.height) if (image.width <= 178 and image.height <= 218) else (178, 218)\n",
        "  trans = transforms.Compose([\n",
        "    transforms.Resize((width, height)), # set the desired size of the image\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  img_tensor=trans(image)\n",
        "  img_tensor = (img_tensor-0.5) /0.5\n",
        "  img_batch=(img_tensor).unsqueeze(0)\n",
        "  img_batch=img_batch.to(device)\n",
        "  return img_batch"
      ],
      "metadata": {
        "id": "gY5zYLbJUfue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_single_channel(encoded_batch):\n",
        "    # Assuming encoded_batch has shape (1, num_channels, H, W)\n",
        "    single_channel_image = torch.mean(encoded_batch[0], dim=0, keepdim=True)  # Average over channels\n",
        "    single_channel_image = single_channel_image.clamp(-1, 1)  # Ensure values are in range [-1, 1]\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    numpy_array = single_channel_image[0].cpu().detach().numpy()\n",
        "\n",
        "    # Normalize values to be in the range [0, 255]\n",
        "    numpy_array = ((numpy_array + 1) / 2 * 255).astype(np.uint8)\n",
        "\n",
        "    # Create a grayscale image\n",
        "    grayscale_image = Image.fromarray(numpy_array, mode='L')\n",
        "\n",
        "    return grayscale_image"
      ],
      "metadata": {
        "id": "s8YQmjEF0MIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compress(img_batch, num_channels):\n",
        "  num_channels_in_encoder = num_channels\n",
        "  netE = Encoder(num_channels_in_encoder).to(device)\n",
        "  netE.apply(weights_init)\n",
        "  netG = Generator(num_channels_in_encoder).to(device)\n",
        "  netG.apply(weights_init)\n",
        "\n",
        "  netE.load_state_dict(torch.load(\"/content/drive/MyDrive/Trained Models/netE\"+str(num_channels)+\".model\"))\n",
        "  netG.load_state_dict(torch.load(\"/content/drive/MyDrive/Trained Models/netG\"+str(num_channels)+\".model\"))\n",
        "\n",
        "  netG.eval()\n",
        "  netE.eval()\n",
        "\n",
        "  encoded_batch = netE(img_batch)\n",
        "\n",
        "  single_channel_image = convert_to_single_channel(encoded_batch)\n",
        "  single_channel_image.save(\"encoded_\"+str(num_channels)+'_image.jpg')\n",
        "\n",
        "  compressed_batch = netG(encoded_batch)\n",
        "\n",
        "  del netE\n",
        "  del netG\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return compressed_batch"
      ],
      "metadata": {
        "id": "ePij5enkUY_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_image(tensor):\n",
        "    tensor = (tensor + 1) / 2\n",
        "    tensor = tensor.cpu().detach()\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return Image.fromarray(tensor.transpose(1,2,0))"
      ],
      "metadata": {
        "id": "XslxK3ZMUZpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PSNR(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
        "                  # Therefore PSNR have no importance.\n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    return psnr"
      ],
      "metadata": {
        "id": "YjP-UoK4qAIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_msssim(original_image, compressed_image, num_scales=5):\n",
        "    msssim = 1.0\n",
        "    weights = np.linspace(0.0448, 0.2856, num=num_scales)  # Default weights for 5 scales\n",
        "\n",
        "    for i in range(num_scales):\n",
        "        # Calculate SSIM for each scale\n",
        "        ssim_val = ssim(original_image, compressed_image, channel_axis=True)\n",
        "\n",
        "        # Calculate the power of SSIM value with the corresponding weight\n",
        "        msssim *= (ssim_val ** weights[i])\n",
        "\n",
        "        # Resize images for the next scale\n",
        "        original_image = original_image[::2, ::2]  # Downsample by a factor of 2\n",
        "        compressed_image = compressed_image[::2, ::2]  # Downsample by a factor of 2\n",
        "\n",
        "    msssim = msssim ** (1 / num_scales)\n",
        "\n",
        "    return msssim"
      ],
      "metadata": {
        "id": "BxovVQc5qJAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_brightness(image_path, brightness_factor=1.2):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Adjust brightness\n",
        "    adjusted_image = cv2.convertScaleAbs(image, alpha=brightness_factor, beta=0)\n",
        "\n",
        "    # Save the adjusted image\n",
        "    cv2.imwrite(image_path, adjusted_image)"
      ],
      "metadata": {
        "id": "y5yABPHCCIfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  img_path = input(\"Enter the image path to compress: \")\n",
        "  image = image_read(img_path)\n",
        "  target= (image.width, image.height) if (image.width < 178 and image.height < 218) else (178, 218)\n",
        "\n",
        "  dictionary = ['compressed_img_8', 'compressed_img_16', 'compressed_img_28', 'compressed_img_40']\n",
        "  dummy_value = None\n",
        "  my_dict = {key: dummy_value for key in dictionary}\n",
        "  channels = [8, 16, 28, 40]\n",
        "\n",
        "  im = image.resize(target)\n",
        "  im.save('resized_original.tif')\n",
        "\n",
        "  im.save('jpg.jpg', quality = 10)\n",
        "  im.save('jpg_.jpg', quality = 80)\n",
        "\n",
        "  img_batch = transform_image(im)\n",
        "  print(\"JPEG: \")\n",
        "  psnr = PSNR(cv2.imread('resized_original.tif'), cv2.imread('/content/jpg.jpg'))\n",
        "  ssim = calculate_msssim(cv2.cvtColor(cv2.imread('resized_original.tif'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('/content/jpg.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "  print(f\"PSNR value is {psnr} dB\")\n",
        "  print(f\"MS-SSIM value is {ssim*100}%\")\n",
        "  print('----------------------------------------------------------')\n",
        "\n",
        "  for key, num_channels in zip(dictionary, channels):\n",
        "    key = compress(img_batch, num_channels)\n",
        "    key = tensor_to_image(key)\n",
        "    key = key.resize(target)\n",
        "    # adjust_brightness('Compressed_img_'+str(num_channels)+'.jpg', brightness_factor=0.8)\n",
        "    key.save('Compressed_img_'+str(num_channels)+'.jpg')\n",
        "\n",
        "    print(\"GAN for \"+str(num_channels)+\" channels\")\n",
        "    psnr = PSNR(cv2.imread('resized_original.tif'), cv2.imread('Compressed_img_'+str(num_channels)+'.jpg'))\n",
        "    ssim = calculate_msssim(cv2.cvtColor(cv2.imread('resized_original.tif'), cv2.COLOR_BGR2GRAY), cv2.cvtColor(cv2.imread('Compressed_img_'+str(num_channels)+'.jpg'), cv2.COLOR_BGR2GRAY))\n",
        "    print(f\"PSNR value is {psnr} dB\")\n",
        "    print(f\"MS-SSIM value is {ssim*100}%\")\n",
        "    print('----------------------------------------------------------')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH30gJG4WTLA",
        "outputId": "7540ca0f-3806-42b4-dc82-1f68b1eb159c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the image path to compress: /content/drive/MyDrive/Images/animation/animation10.tif\n",
            "JPEG: \n",
            "PSNR value is 29.99303324412451 dB\n",
            "MS-SSIM value is 96.82574352224371%\n",
            "----------------------------------------------------------\n",
            "GAN for 8 channels\n",
            "PSNR value is 28.727431475527844 dB\n",
            "MS-SSIM value is 97.43022882830893%\n",
            "----------------------------------------------------------\n",
            "GAN for 16 channels\n",
            "PSNR value is 29.916349576590143 dB\n",
            "MS-SSIM value is 97.85064920228471%\n",
            "----------------------------------------------------------\n",
            "GAN for 28 channels\n",
            "PSNR value is 30.707623261810852 dB\n",
            "MS-SSIM value is 97.10240896334828%\n",
            "----------------------------------------------------------\n",
            "GAN for 40 channels\n",
            "PSNR value is 30.3471620373532 dB\n",
            "MS-SSIM value is 98.24094343096965%\n",
            "----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qNGdBs8YSx6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}